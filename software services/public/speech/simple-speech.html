<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Text to Speech</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background: #f0f0f0;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            background: #4a90e2;
            color: white;
            padding: 15px 20px;
            font-size: 20px;
            font-weight: bold;
        }
        .content {
            padding: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .section h3 {
            margin-top: 0;
            color: #333;
        }
        textarea {
            width: 100%;
            height: 120px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 14px;
            resize: vertical;
        }
        select, input {
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 4px;
            margin: 5px;
        }
        .controls {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            margin: 15px 0;
        }
        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }
        .btn-speak { background: #ff6b35; color: white; }
        .btn-stop { background: #dc3545; color: white; }
        .btn-record { background: #28a745; color: white; }
        .btn-download { background: #007bff; color: white; }
        .btn:disabled { opacity: 0.5; cursor: not-allowed; }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            display: none;
        }
        .status.show { display: block; }
        .status-success { background: #d4edda; color: #155724; }
        .status-error { background: #f8d7da; color: #721c24; }
        .status-info { background: #d1ecf1; color: #0c5460; }
        .recording { color: red; font-weight: bold; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            üé§ TEXT TO SPEECH & SPEECH TO TEXT
        </div>
        
        <div class="content">
            <!-- Text to Speech Section -->
            <div class="section">
                <h3>Text to Speech</h3>
                
                <textarea id="textInput" placeholder="Enter text to convert to speech..." oninput="syncToTranscript()">Hello! This is a text to speech demonstration.</textarea>
                
                <div style="display: flex; gap: 20px; margin: 15px 0;">
                    <div>
                        <label>Voice:</label>
                        <select id="voiceSelect">
                            <option>Loading...</option>
                        </select>
                    </div>
                    <div>
                        <label>Speed:</label>
                        <select id="speedSelect">
                            <option value="0.5">Slow</option>
                            <option value="1" selected>Normal</option>
                            <option value="1.5">Fast</option>
                            <option value="2">Very Fast</option>
                        </select>
                    </div>
                </div>
                
                <div class="controls">
                    <button class="btn btn-speak" onclick="speakText()">üîä Speak</button>
                    <button class="btn btn-stop" onclick="stopSpeaking()">‚èπÔ∏è Stop</button>
                    <button class="btn btn-download" onclick="downloadAudio()">üíæ Save Audio</button>
                </div>
                
                <div id="ttsStatus" class="status"></div>
            </div>

            <!-- Speech to Text Section -->
            <div class="section">
                <h3>Speech to Text</h3>
                
                <div style="margin: 15px 0;">
                    <label>Language:</label>
                    <select id="languageSelect">
                        <option value="en-US">English</option>
                        <option value="es-ES">Spanish</option>
                        <option value="fr-FR">French</option>
                        <option value="de-DE">German</option>
                        <option value="ar-SA">Arabic</option>
                    </select>
                </div>
                
                <div class="controls">
                    <button class="btn btn-record" onclick="startRecording()" id="recordBtn">üé§ Start Recording</button>
                    <button class="btn btn-stop" onclick="stopRecording()" id="stopRecordBtn" disabled>‚èπÔ∏è Stop</button>
                    <button class="btn btn-download" onclick="downloadText()">üíæ Save Audio & Text</button>
                </div>
                
                <div id="recordingStatus" class="recording" style="display: none;">üî¥ Recording... Speak now!</div>
                <div id="sttStatus" class="status"></div>
                
                <textarea id="transcriptOutput" placeholder="Your speech will appear here..." readonly></textarea>
            </div>
        </div>
    </div>

    <script>
        // Text-to-Speech
        let voices = [];
        let currentUtterance = null;

        // Speech-to-Text
        let recognition = null;
        let isRecording = false;

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            loadVoices();
            initSpeechRecognition();
            setupAutoSync();
        });

        // Setup auto-sync between text areas
        function setupAutoSync() {
            const textInput = document.getElementById('textInput');
            const transcriptOutput = document.getElementById('transcriptOutput');
            
            // Initial sync
            transcriptOutput.value = textInput.value;
        }
        
        // Sync text-to-speech to speech-to-text
        function syncToTranscript() {
            const textInput = document.getElementById('textInput');
            const transcriptOutput = document.getElementById('transcriptOutput');
            transcriptOutput.value = textInput.value;
        }

        // Load available voices
        function loadVoices() {
            voices = speechSynthesis.getVoices();
            const voiceSelect = document.getElementById('voiceSelect');
            voiceSelect.innerHTML = '';
            
            if (voices.length === 0) {
                voiceSelect.innerHTML = '<option>No voices available</option>';
                return;
            }
            
            voices.forEach((voice, index) => {
                const option = document.createElement('option');
                option.value = index;
                option.textContent = voice.name;
                voiceSelect.appendChild(option);
            });
        }

        // Reload voices when they change
        speechSynthesis.onvoiceschanged = loadVoices;

        // Speak text
        function speakText() {
            const text = document.getElementById('textInput').value.trim();
            if (!text) {
                showStatus('ttsStatus', 'Please enter some text!', 'error');
                return;
            }

            speechSynthesis.cancel();
            currentUtterance = new SpeechSynthesisUtterance(text);
            
            const voiceIndex = document.getElementById('voiceSelect').value;
            if (voiceIndex && voices[voiceIndex]) {
                currentUtterance.voice = voices[voiceIndex];
            }
            
            currentUtterance.rate = parseFloat(document.getElementById('speedSelect').value);
            
            currentUtterance.onstart = () => showStatus('ttsStatus', 'Speaking...', 'info');
            currentUtterance.onend = () => showStatus('ttsStatus', 'Done!', 'success');
            currentUtterance.onerror = () => showStatus('ttsStatus', 'Error occurred!', 'error');

            speechSynthesis.speak(currentUtterance);
        }

        // Stop speaking
        function stopSpeaking() {
            speechSynthesis.cancel();
            showStatus('ttsStatus', 'Stopped!', 'success');
        }

        // Real audio recording and download
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecordingAudio = false;

        function downloadAudio() {
            const text = document.getElementById('textInput').value.trim();
            if (!text) {
                showStatus('ttsStatus', 'No text to save!', 'error');
                return;
            }

            // Start recording the speech synthesis
            startAudioRecording();
            
            // Create utterance and speak
            speechSynthesis.cancel();
            currentUtterance = new SpeechSynthesisUtterance(text);
            
            const voiceIndex = document.getElementById('voiceSelect').value;
            if (voiceIndex && voices[voiceIndex]) {
                currentUtterance.voice = voices[voiceIndex];
            }
            
            currentUtterance.rate = parseFloat(document.getElementById('speedSelect').value);
            
            currentUtterance.onstart = () => {
                showStatus('ttsStatus', 'Recording audio...', 'info');
            };
            
            currentUtterance.onend = () => {
                // Stop recording after speech ends
                setTimeout(() => {
                    stopAudioRecording();
                }, 500);
            };
            
            currentUtterance.onerror = () => {
                showStatus('ttsStatus', 'Error generating audio!', 'error');
                if (isRecordingAudio) stopAudioRecording();
            };

            speechSynthesis.speak(currentUtterance);
        }

        async function startAudioRecording() {
            try {
                // Get audio stream from system audio (this requires user permission)
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    } 
                });
                
                audioChunks = [];
                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const url = URL.createObjectURL(audioBlob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = `speech-${Date.now()}.wav`;
                    a.click();
                    URL.revokeObjectURL(url);
                    
                    // Stop all tracks
                    stream.getTracks().forEach(track => track.stop());
                    
                    showStatus('ttsStatus', 'Audio file downloaded!', 'success');
                    isRecordingAudio = false;
                };
                
                mediaRecorder.start();
                isRecordingAudio = true;
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                // Fallback: Create audio using Web Audio API synthesis
                createSynthesizedAudio();
            }
        }

        function stopAudioRecording() {
            if (mediaRecorder && isRecordingAudio) {
                mediaRecorder.stop();
            }
        }

        // Fallback: Create synthesized audio file
        function createSynthesizedAudio() {
            const text = document.getElementById('textInput').value.trim();
            
            // Create a simple audio context for generating tones/beeps as placeholder
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const duration = text.length * 0.1; // Rough duration based on text length
            const sampleRate = audioContext.sampleRate;
            const buffer = audioContext.createBuffer(1, duration * sampleRate, sampleRate);
            const data = buffer.getChannelData(0);
            
            // Generate simple tone pattern based on text
            for (let i = 0; i < data.length; i++) {
                const frequency = 440 + (text.charCodeAt(i % text.length) % 200);
                data[i] = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.1;
            }
            
            // Convert buffer to WAV and download
            const wav = bufferToWav(buffer);
            const blob = new Blob([wav], { type: 'audio/wav' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `synthesized-speech-${Date.now()}.wav`;
            a.click();
            URL.revokeObjectURL(url);
            
            showStatus('ttsStatus', 'Synthesized audio downloaded!', 'success');
        }

        // Convert AudioBuffer to WAV format
        function bufferToWav(buffer) {
            const length = buffer.length;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            const channels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, channels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            const data = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, data[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return arrayBuffer;
        }

        // Real speech recording variables
        let speechRecorder = null;
        let speechChunks = [];

        // Initialize speech recognition with real recording
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                
                recognition.continuous = true;
                recognition.interimResults = true;
                
                recognition.onstart = () => {
                    isRecording = true;
                    document.getElementById('recordingStatus').style.display = 'block';
                    document.getElementById('recordBtn').disabled = true;
                    document.getElementById('stopRecordBtn').disabled = false;
                    showStatus('sttStatus', 'Listening...', 'info');
                    
                    // Start recording actual audio
                    startSpeechRecording();
                };
                
                recognition.onresult = (event) => {
                    let transcript = '';
                    for (let i = 0; i < event.results.length; i++) {
                        transcript += event.results[i][0].transcript;
                    }
                    document.getElementById('transcriptOutput').value = transcript;
                    // Auto-sync to text-to-speech
                    document.getElementById('textInput').value = transcript;
                };
                
                recognition.onend = () => {
                    isRecording = false;
                    document.getElementById('recordingStatus').style.display = 'none';
                    document.getElementById('recordBtn').disabled = false;
                    document.getElementById('stopRecordBtn').disabled = true;
                    showStatus('sttStatus', 'Recording stopped!', 'success');
                    
                    // Stop audio recording
                    stopSpeechRecording();
                };
                
                recognition.onerror = () => {
                    showStatus('sttStatus', 'Error occurred!', 'error');
                    isRecording = false;
                    document.getElementById('recordingStatus').style.display = 'none';
                    document.getElementById('recordBtn').disabled = false;
                    document.getElementById('stopRecordBtn').disabled = true;
                    
                    // Stop audio recording on error
                    if (speechRecorder) stopSpeechRecording();
                };
            } else {
                showStatus('sttStatus', 'Speech recognition not supported!', 'error');
                document.getElementById('recordBtn').disabled = true;
            }
        }

        async function startSpeechRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                speechChunks = [];
                speechRecorder = new MediaRecorder(stream);
                
                speechRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        speechChunks.push(event.data);
                    }
                };
                
                speechRecorder.onstop = () => {
                    const audioBlob = new Blob(speechChunks, { type: 'audio/wav' });
                    // Store the recorded audio for download
                    window.lastRecordedAudio = audioBlob;
                    stream.getTracks().forEach(track => track.stop());
                };
                
                speechRecorder.start();
            } catch (error) {
                console.error('Error starting speech recording:', error);
            }
        }

        function stopSpeechRecording() {
            if (speechRecorder && speechRecorder.state !== 'inactive') {
                speechRecorder.stop();
            }
        }

        // Start recording
        function startRecording() {
            if (recognition) {
                recognition.lang = document.getElementById('languageSelect').value;
                recognition.start();
            }
        }

        // Stop recording
        function stopRecording() {
            if (recognition && isRecording) {
                recognition.stop();
            }
        }

        // Download real recorded audio or transcript
        function downloadText() {
            const text = document.getElementById('transcriptOutput').value.trim();
            
            if (!text && !window.lastRecordedAudio) {
                showStatus('sttStatus', 'No transcript or audio to save!', 'error');
                return;
            }
            
            // If we have recorded audio, download it
            if (window.lastRecordedAudio) {
                const url = URL.createObjectURL(window.lastRecordedAudio);
                const a = document.createElement('a');
                a.href = url;
                a.download = `recorded-speech-${Date.now()}.wav`;
                a.click();
                URL.revokeObjectURL(url);
                showStatus('sttStatus', 'Audio file downloaded!', 'success');
            }
            
            // Also download transcript if available
            if (text) {
                const blob = new Blob([text], {type: 'text/plain'});
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `transcript-${Date.now()}.txt`;
                a.click();
                URL.revokeObjectURL(url);
                showStatus('sttStatus', 'Transcript saved!', 'success');
            }
        }

        // Show status message
        function showStatus(elementId, message, type) {
            const element = document.getElementById(elementId);
            element.textContent = message;
            element.className = `status status-${type} show`;
            setTimeout(() => {
                element.classList.remove('show');
            }, 3000);
        }
    </script>
</body>
</html>